{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LearningRate-Optimization.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOOK7kxwh5zmZPDFhHkuUSi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RNXuTPwqMjAQ","colab_type":"code","outputId":"a9d8f018-c015-40a4-a21c-43d70c0f05da","executionInfo":{"status":"ok","timestamp":1581627347010,"user_tz":300,"elapsed":9700,"user":{"displayName":"Pedram Khayyatkhoshnevis","photoUrl":"","userId":"14668972162109202832"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","import torch\n","\n","from torch.nn import Conv1d\n","\n","from torch.nn import MaxPool1d\n","\n","from torch.nn import Flatten\n","\n","from torch.nn import Linear\n","\n","from torch.nn.functional import relu\n","\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","from torch.optim import SGD\n","\n","from torch.nn import L1Loss\n","\n","!pip install pytorch-ignite\n","\n","from ignite.contrib.metrics.regression.r2_score import R2Score"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytorch-ignite\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/55/41e8a995876fd2ade29bdba0c3efefa38e7d605cb353c70f3173c04928b5/pytorch_ignite-0.3.0-py2.py3-none-any.whl (103kB)\n","\r\u001b[K     |███▏                            | 10kB 27.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20kB 29.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 30kB 33.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40kB 25.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 51kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 61kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 71kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 81kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 92kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 102kB 12.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 12.1MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.4.0)\n","Installing collected packages: pytorch-ignite\n","Successfully installed pytorch-ignite-0.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PW59khdv4PUj","colab_type":"code","colab":{}},"source":["class CnnRegressor(torch.nn.Module):\n","\n","  def __init__(self, batch_size, inputs, outputs, kernelsize):\n","\n","    super(CnnRegressor, self).__init__()\n","    self.batch_size = batch_size\n","    self.inputs = inputs\n","    self.outputs = outputs\n","\n","    self.input_layer = Conv1d(inputs, batch_size, kernelsize)\n","\n","    self.max_pooling_layer = MaxPool1d(1)\n","\n","    self.conv_layer = Conv1d(batch_size, 128, kernelsize)\n","\n","    self.flatten_layer = Flatten()\n","\n","    self.linear_layer = Linear(128, 64)\n","\n","    self.output_layer = Linear(64, outputs)\n","\n","  \n","  def feed(self, input):\n","\n","    input = input.reshape((self.batch_size, self.inputs, 1))\n","\n","    output = relu(self.input_layer(input))\n","\n","    output = self.max_pooling_layer(output)\n","\n","    output = relu(self.conv_layer(output))\n","\n","    output = self.flatten_layer(output)\n","\n","    output = self.linear_layer(output)\n","\n","    output = self.output_layer(output)\n","\n","    return output\n","\n","def model_loss(model, dataset, train = False, optimizer = 'adam'):\n","\n","  performance = L1Loss()\n","  score_metric = R2Score()\n","\n","  avg_loss = 0\n","  avg_score = 0\n","  count = 0\n","\n","  for input, output in iter(dataset):\n","\n","    predictions = model.feed(input)\n","\n","    loss = performance(predictions, output)\n","\n","    score_metric.update([predictions, output])\n","    score = score_metric.compute()\n","        \n","    if(train):\n","\n","      optimizer.zero_grad()\n","\n","      loss.backward()\n","\n","      optimizer.step()\n","\n","    avg_loss += loss.item()\n","    avg_score += score\n","    count += 1\n","\n","  return avg_loss / count, avg_score / count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhoAhIINsOuG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"c2fb9fdf-2869-44c0-d8e3-21e02cb80ea5","executionInfo":{"status":"error","timestamp":1581627347013,"user_tz":300,"elapsed":9697,"user":{"displayName":"Pedram Khayyatkhoshnevis","photoUrl":"","userId":"14668972162109202832"}}},"source":["dataset = pd.read_csv('housing.csv')\n","\n","dataset = dataset.dropna()"],"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-0b7fbc3e7a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'housing.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'housing.csv' does not exist: b'housing.csv'"]}]},{"cell_type":"code","metadata":{"id":"up3y8A6xstLZ","colab_type":"code","colab":{}},"source":["Y = dataset['median_house_value']\n","X = dataset.loc[:,'longitude':'median_income']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfO1oOAjtSl5","colab_type":"code","colab":{}},"source":["# 30% for testing dataset\n","__testPercent__ = 0.3\n","x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=__testPercent__)\n","\n","x_train_np = x_train.to_numpy()\n","\n","y_train_np = y_train.to_numpy()\n","\n","x_test_np = x_test.to_numpy()\n","y_test_np = y_test.to_numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0D-cNReMtbLc","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"LdhBwD4G3S-Y","colab_type":"code","colab":{}},"source":["ResultArry = {}\n","\n","for x in range(0,8):\n","\n","  learning_rates = [1E-0, 1E-1, 1E-2, 1E-3, 1E-4, 1E-5, 1E-6, 1E-7]\n","\n","  batch_size = 38\n","\n","  kernelSize = 1\n","\n","  model = CnnRegressor(batch_size, X.shape[1], 1,kernelSize)\n","\n","  model.cuda()\n","\n","  epochs = 30\n","\n","  # To see and compare the final results\n","  currentID = \"learningrate-\"+str(learning_rates[x])\n","\n","  optimizer = SGD(model.parameters(), lr=learning_rates[x])\n","  \n","  inputs = torch.from_numpy(x_train_np).cuda().float()\n","  outputs = torch.from_numpy(y_train_np.reshape(y_train_np.shape[0],1)).cuda().float()\n","\n","  tensor = TensorDataset(inputs, outputs)\n","\n","  loader = DataLoader(tensor, batch_size, shuffle=True, drop_last=True)\n","\n","  for epoch in range(epochs):\n","    avg_loss, avg_r2_score = model_loss(model, loader, train=True, optimizer=optimizer)\n","    # print(\"Epoch \"+ str(epoch + 1) + \":\\n\\tLoss = \" + str(avg_loss) + \"\\n\\r R2 score = \" + str(avg_r2_score)  )\n","\n","  inputs = torch.from_numpy(x_test_np).cuda().float()\n","  outputs = torch.from_numpy(y_test_np.reshape(y_test_np.shape[0],1)).cuda().float()\n","\n","  tensor = TensorDataset(inputs, outputs)\n","  loader = DataLoader(tensor, batch_size, shuffle=True, drop_last=True)\n","\n","  avg_loss, avg_r2_score = model_loss(model, loader)\n","  # print(\"the model L1 loss is: \" + str(avg_loss))\n","  # print(\"the model R2 score is: \" + str(avg_r2_score))\n","\n","  ResultArry.update({currentID:avg_r2_score})\n","\n","  print(\"now:\"+str(currentID)+' ++')\n","  print(ResultArry)\n","\n","print(ResultArry)\n","#get max accuracy\n","maxkey=0\n","maxval = -9999999\n","for key in ResultArry:\n","  if(ResultArry[key]>maxval):\n","      maxval = ResultArry[key]\n","      maxkey = key\n","\n","print('best result was for:')\n","if(maxkey!=0):\n","  print(str(maxkey) + ' -> ' + str(ResultArry[maxkey]))\n","\n","print(learning_rates)"],"execution_count":0,"outputs":[]}]}